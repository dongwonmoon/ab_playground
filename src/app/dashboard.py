import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

from src.utils.config_loader import load_config
from src.utils.mlflow_loader import MLflowLoader
from src.simulation.simulator import ABTestSimulator
from src.ab_testing import frequentist_engine, bayesian_engine
from src.data.preprocessing import mapping_id_to_unique

import time

# --- 1. í˜ì´ì§€ ì„¤ì • ë° ì œëª© ---
st.set_page_config(layout="wide", page_title="A/B Test Decision Dashboard")
st.title("ğŸ“ˆ A/B í…ŒìŠ¤íŠ¸ ì˜ì‚¬ê²°ì • ëŒ€ì‹œë³´ë“œ")
st.markdown("SVD(Baseline) vs NCF(Challenger) ì¶”ì²œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„")


# --- 2. ë°ì´í„° ë° ëª¨ë¸ ë¡œë”© (ìºì‹± í™œìš©) ---
@st.cache_data
def load_all_data(config):
    print("Loading data...")
    test_df = pd.read_parquet(config["data"]["test_data_path"])
    full_df = pd.read_parquet(config["data"]["processed_path"])

    _, _, mapped_test_df = mapping_id_to_unique(full_df, test_df.copy())
    _, _, mapped_full_df = mapping_id_to_unique(full_df, full_df.copy())
    return mapped_test_df, mapped_full_df


@st.cache_resource
def load_models_from_mlflow(config):
    print("Loading models from MLflow...")
    mlflow_config = config["mlflow"]
    loader = MLflowLoader(
        tracking_uri=mlflow_config["tracking_uri"],
        experiment_name=mlflow_config["experiment_name"],
    )
    runs = loader.get_latest_runs()
    models = loader.load_models(runs)
    return loader, models


# --- 3. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---
def run_full_simulation(simulator, model_a, model_b, top_k, success_threshold) -> dict:
    """ê²°ê³¼ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” í•¨ìˆ˜"""
    results = simulator.run_simulation(
        model_a=model_a,
        model_b=model_b,
        top_k=top_k,
        success_threshold=success_threshold,
    )
    return results


def plot_beta_distributions(visitors_a, conversions_a, visitors_b, conversions_b):
    """ë² íƒ€ ë¶„í¬ ì‹œê°í™” í•¨ìˆ˜"""
    fig, ax = plt.subplots(figsize=(10, 5))

    # A ê·¸ë£¹
    alpha_a = conversions_a + 1
    beta_a = visitors_a - conversions_a + 1

    # B ê·¸ë£¹
    alpha_b = conversions_b + 1
    beta_b = visitors_b - conversions_b + 1

    # xì¶•
    x = np.linspace(0, max(alpha_a / visitors_a, alpha_b / visitors_b) + 0.05, 1000)

    # ê° ê·¸ë£¹ì˜ ë² íƒ€ ë¶„í¬ PDF ê³„ì‚°
    y_a = stats.beta.pdf(x, alpha_a, beta_a)
    y_b = stats.beta.pdf(x, alpha_b, beta_b)

    ax.plot(x, y_a, label=f"Model A (SVD) - CTR: {conversions_a/visitors_a:.2%}")
    ax.plot(x, y_b, label=f"Model B (NCF) - CTR: {conversions_b/visitors_b:.2%}")
    ax.legend()
    ax.set_title("Beta Distribution of Conversion Rates", fontsize=15)
    ax.set_xlabel("Conversion Rate (CTR)", fontsize=12)
    ax.set_ylabel("Probability Density", fontsize=12)

    return fig


# --- 4. ë©”ì¸ ëŒ€ì‹œë³´ë“œ ë¡œì§ ---
config = load_config("configs/config.yml")
test_df, full_df = load_all_data(config)
loader, models = load_models_from_mlflow(config)
model_a = models.get("SVD_PYTORCH")
model_b = models.get("NCF")

# ì‚¬ì´ë“œë°”: ì‚¬ìš©ì ì»¨íŠ¸ë¡¤
st.sidebar.header("âš™ï¸ Simulation Controls")
max_value = int(len(test_df) // 2)
num_users_a = st.sidebar.number_input(
    "A ê·¸ë£¹(SVD) ì‚¬ìš©ì ìˆ˜", min_value=100, max_value=max_value, value=1000, step=100
)
num_users_b = st.sidebar.number_input(
    "B ê·¸ë£¹(NCF) ì‚¬ìš©ì ìˆ˜", min_value=100, max_value=max_value, value=1000, step=100
)
top_k = st.sidebar.slider("Top-K ì¶”ì²œ", min_value=5, max_value=50, value=10)
success_threshold = st.sidebar.slider(
    "ì„±ê³µ ê¸°ì¤€ í‰ì ", min_value=0.5, max_value=5.0, value=4.0, step=0.5
)

if st.sidebar.button("ğŸš€ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰!"):
    # 1. ì‹œë®¬ë ˆì´í„° ë° ìºì‹œ ì´ˆê¸°í™”
    simulator = ABTestSimulator(full_df, test_df)
    simulator.set_group_num(num_A=num_users_a, num_B=num_users_b)

    # 2. ì‹œë®¬ë ˆì´ì…˜ ë° ë¶„ì„ ì‹¤í–‰
    analysis_results = {}
    sim_results = run_full_simulation(
        simulator, model_a, model_b, top_k, success_threshold
    )
    analysis_results["p_value"] = frequentist_engine.get_p_value(
        sim_results["conversions_a"],
        sim_results["visitors_a"],
        sim_results["conversions_b"],
        sim_results["visitors_b"],
    )
    analysis_results["prob_b_better"], analysis_results["expected_uplift"] = (
        bayesian_engine.get_bayesian_result(
            sim_results["conversions_a"],
            sim_results["visitors_a"],
            sim_results["conversions_b"],
            sim_results["visitors_b"],
        )
    )

    # ---------------------------------
    # ì„¹ì…˜ 1: ìµœì¢… ê²°ë¡ 
    # ---------------------------------
    st.header("1. ìµœì¢… ê²°ë¡ ")
    recommendation = ""
    recommendation_reason = ""
    if (
        analysis_results["prob_b_better"] > 0.95
        and analysis_results["expected_uplift"] > 0
    ):
        recommendation = "ëª¨ë¸ B (Challenger)ë¡œì˜ ì „í™˜ì„ ê¶Œê³ í•©ë‹ˆë‹¤."
        recommendation_reason = f"ëª¨ë¸ BëŠ” ê¸°ì¡´ ëª¨ë¸ A ëŒ€ë¹„ ì „í™˜ìœ¨ì„ ì•½ **{analysis_results['expected_uplift']:.2%}** í–¥ìƒì‹œí‚¬ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë˜ë©°, ì´ ê²°ê³¼ëŠ” í†µê³„ì ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (Bê°€ ë” ë‚˜ì„ í™•ë¥ : **{analysis_results['prob_b_better']:.2%}**)."
        st.success(f"**ê²°ë¡ : {recommendation}**")
        st.markdown(recommendation_reason)
    else:
        recommendation = "ëª¨ë¸ A (Baseline) ìœ ì§€ë¥¼ ê¶Œê³ í•©ë‹ˆë‹¤."
        recommendation_reason = f"ëª¨ë¸ Bì˜ ì„±ëŠ¥ í–¥ìƒì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ìˆ˜ì¤€ì— ë„ë‹¬í•˜ì§€ ëª»í–ˆê±°ë‚˜, ê¸°ëŒ€ í–¥ìƒì¹˜ê°€ ë¯¸ë¯¸í•˜ì—¬ ì „í™˜ì˜ ê·¼ê±°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (Bê°€ ë” ë‚˜ì„ í™•ë¥ : **{analysis_results['prob_b_better']:.2%}**)."
        st.info(f"**ê²°ë¡ : {recommendation}**")
        st.markdown(recommendation_reason)

    # ---------------------------------
    # ì„¹ì…˜ 2: A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìƒì„¸ ë¶„ì„`
    # ---------------------------------`
    st.header("2. A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìƒì„¸ ë¶„ì„")
    ctr_a = sim_results["conversions_a"] / sim_results["visitors_a"]
    ctr_b = sim_results["conversions_b"] / sim_results["visitors_b"]

    st.markdown("#### ê¸°ë³¸ ê²°ê³¼ ìš”ì•½")
    col1, col2, col3 = st.columns(3)
    col1.metric("A (SVD) ë°©ë¬¸ì", f"{sim_results['visitors_a']:,} ëª…")
    col2.metric("A (SVD) ì „í™˜", f"{sim_results['conversions_a']:,} ê±´")
    col3.metric("A (SVD) ì „í™˜ìœ¨", f"{ctr_a:.3%}")

    col1, col2, col3 = st.columns(3)
    col1.metric("B (Challenger) ë°©ë¬¸ì", f"{sim_results['visitors_b']:,} ëª…")
    col2.metric("B (Challenger) ì „í™˜", f"{sim_results['conversions_b']:,} ê±´")
    col3.metric("B (Challenger) ì „í™˜ìœ¨", f"{ctr_b:.3%}")

    st.divider()

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ë¹ˆë„ì£¼ì˜ ë¶„ì„")
        st.metric("P-value", f"{analysis_results['p_value']:.4f}")
        if analysis_results["p_value"] < 0.05:
            st.markdown(
                "âœ… **ê²°ë¡ **: ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ ì°¨ì´ëŠ” **í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸**í•©ë‹ˆë‹¤ (p < 0.05)."
            )
        else:
            st.markdown(
                "âš ï¸ **ê²°ë¡ **: ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ë‹¤ê³  ë³´ê¸° **ì–´ë µìŠµë‹ˆë‹¤** (p >= 0.05)."
            )

    with col2:
        st.subheader("ë² ì´ì§€ì•ˆ ë¶„ì„")
        st.metric("Bê°€ ë” ìš°ìˆ˜í•  í™•ë¥ ", f"{analysis_results['prob_b_better']:.2%}")
        st.metric(
            "Bì˜ ìƒëŒ€ì  ì„±ëŠ¥ í–¥ìƒ ê¸°ëŒ€ì¹˜", f"{analysis_results['expected_uplift']:.2%}"
        )
        st.markdown(
            "âœ… **ê²°ë¡ **: B ëª¨ë¸ë¡œ ì „í™˜ ì‹œ, **ì•½ 99%ì˜ í™•ë¥ ë¡œ ì„±ëŠ¥ì´ í–¥ìƒ**ë˜ë©° **13.6%ì˜ ì„±ëŠ¥ ê°œì„ ì„ ê¸°ëŒ€**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            if analysis_results["prob_b_better"] > 0.95
            else "âš ï¸ **ê²°ë¡ **: B ëª¨ë¸ì˜ ìš°ì›”ì„±ì— ëŒ€í•œ **í™•ì‹ ì´ ë¶€ì¡±**í•©ë‹ˆë‹¤."
        )

    # ë² íƒ€ ë¶„í¬ ì‹œê°í™”
    st.subheader("CTR ì‹ ë¢°ë„ ë¶„í¬ (Beta Distribution)")
    beta_fig = plot_beta_distributions(
        sim_results["visitors_a"],
        sim_results["conversions_a"],
        sim_results["visitors_b"],
        sim_results["conversions_b"],
    )
    st.pyplot(beta_fig)

    # ---------------------------------
    # ì„¹ì…˜ 3: ë¹„ìš©-íš¨ê³¼ ë¶„ì„
    # ---------------------------------
    st.header("3. ë¹„ìš©-íš¨ê³¼ ë¶„ì„")
    st.markdown(
        "ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ì¶”ê°€ì ì¸ ë¹„ìš©(í•™ìŠµ/ì¶”ë¡  ì‹œê°„, ì„œë¹™ ë¹„ìš©)ì„ ê°ìˆ˜í•  ê°€ì¹˜ê°€ ìˆëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤."
    )

    # met_par = loader.get_run_metrics_and_params(loader.get_latest_runs())
    # svd_pytorch_par = met_par.get("SVD_PYTORCH", {}).get("params", {})
    # ncf_par = met_par.get("NCF", {}).get("params", {})
    # cost_data = {
    #     "ì§€í‘œ": [
    #         "ì„±ëŠ¥ í–¥ìƒ ê¸°ëŒ€ì¹˜",
    #         "í•™ìŠµ ì‹œê°„ (ì´ˆ)",
    #         "ì¶”ë¡  ì†ë„ (ì´ˆ/1k users)",
    #         "ëª¨ë¸ í¬ê¸° (KB)",
    #     ],
    #     "ëª¨ë¸ A (SVD_Pytorch)": [
    #         f"Baseline",
    #         f"{svd_pytorch_par.get('training_time', 0)}",
    #         f"{1000 * svd_time / len(simulator.get_group_a):.2f}",
    #     ],
    #     "ëª¨ë¸ B (Challenger)": [
    #         f"+{analysis_results['expected_uplift']:.2%}",
    #         f"{ncf_par.get('training_time', 0)}",
    #         f"{1000 * ncf_time / len(simulator.get_group_b):.2f}",
    #     ],
    # }
    # cost_df = pd.DataFrame(cost_data)
    # st.table(cost_df.set_index("ì§€í‘œ"))

else:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ì„ ì¡°ì •í•œ í›„ 'ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
